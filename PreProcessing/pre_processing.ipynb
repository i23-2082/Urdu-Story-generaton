{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a986116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59955235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text sample:\n",
      "0      ارسلان خان\\nشیر جنگل میں آرام کر رہا تھا کہ اس...\n",
      "1      جاوید اقبال\\nایک دن دوستوں کا بیٹھے بیٹھے گاؤں...\n",
      "2      محمد سراج الدین\\nمیں ایک بلی ہوں۔میرا رنگ سفید...\n",
      "3      محمد فاروق دانش\\n”ارے بے وقوف! بات تو سنو․․․․“...\n",
      "4      فرحی نعیم\\nسامنے والے اسلم انکل جب سے ابو جان ...\n",
      "                             ...                        \n",
      "104    زبیدہ سلطانہ\\nنتھوایک خانہ بدوش قبیلے سے تعلق ...\n",
      "105    بینش جمیل:\\nبہت مدت پہلے دور دراز کے ایک ملک م...\n",
      "106    جاوید اقبال :\\nلمبی اور بھاری چونج والا پرندہ ...\n",
      "107    میں ایک صاف ستھرے گھر میں رہتا تھا۔ میرا مالک ...\n",
      "108    جاوید بسام:\\nوہ دن میاں بلاقی کیلئے انتہائی حی...\n",
      "Name: content, Length: 109, dtype: object\n",
      "\n",
      "==================================================\n",
      "\n",
      "After preprocessing:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter preprocessing:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpreprocess_urdu_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mpreprocess_urdu_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_urdu_text\u001b[39m(text):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply all preprocessing steps\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mremove_english_characters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     text \u001b[38;5;241m=\u001b[39m normalize_unicode(text)\n\u001b[1;32m     26\u001b[0m     text \u001b[38;5;241m=\u001b[39m standardize_punctuation(text)\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mremove_english_characters\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_english_characters\u001b[39m(text):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Remove English characters (a-z, A-Z) from text while keeping Urdu and digits\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[a-zA-Z]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/re.py:209\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def remove_english_characters(text):\n",
    "    \"\"\"Remove English characters (a-z, A-Z) from text while keeping Urdu and digits\"\"\"\n",
    "    return re.sub(r'[a-zA-Z]', '', text)\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    \"\"\"Normalize Unicode to NFC form for consistent representation\"\"\"\n",
    "    return unicodedata.normalize('NFC', text)\n",
    "\n",
    "def standardize_punctuation(text):\n",
    "    \"\"\"Standardize common punctuation marks\"\"\"\n",
    "    # Replace various dashes and hyphens with a standard one\n",
    "    text = re.sub(r'[-–—]', '-', text)\n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove extra punctuation at the end\n",
    "    text = re.sub(r'([۔؟!])\\1+', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_urdu_text(text):\n",
    "    \"\"\"Apply all preprocessing steps\"\"\"\n",
    "    text = remove_english_characters(text)\n",
    "    text = normalize_unicode(text)\n",
    "    text = standardize_punctuation(text)\n",
    "    return text.strip()\n",
    "\n",
    "# Test the functions with sample data\n",
    "df = pd.read_csv('all_urdu_moral_stories.csv')\n",
    "print(\"Original text sample:\")\n",
    "print(df['content'])\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"After preprocessing:\")\n",
    "print(preprocess_urdu_text(df['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1018c037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete!\n",
      "Total rows processed: 109\n",
      "Output saved to: all_urdu_moral_stories_preprocessed.csv\n",
      "\n",
      "Sample comparison:\n",
      "Original: ارسلان خان\n",
      "شیر جنگل میں آرام کر رہا تھا کہ اس نے بلی کو دیکھا تو اسے آواز دے کر بلایا۔شیر نے بلی سے \n",
      "Cleaned:  ارسلان خان شیر جنگل میں آرام کر رہا تھا کہ اس نے بلی کو دیکھا تو اسے آواز دے کر بلایا۔شیر نے بلی سے \n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to all content and save to new CSV\n",
    "df = pd.read_csv('all_urdu_moral_stories.csv')\n",
    "\n",
    "# Apply preprocessing to the content column\n",
    "df['content_cleaned'] = df['content'].apply(preprocess_urdu_text)\n",
    "\n",
    "# Save the preprocessed data to a new CSV file\n",
    "output_file = 'all_urdu_moral_stories_preprocessed.csv'\n",
    "df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Preprocessing complete!\")\n",
    "print(f\"Total rows processed: {len(df)}\")\n",
    "print(f\"Output saved to: {output_file}\")\n",
    "print(\"\\nSample comparison:\")\n",
    "print(f\"Original: {df['content'].iloc[0][:100]}\")\n",
    "print(f\"Cleaned:  {df['content_cleaned'].iloc[0][:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c81d3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns removed: title, subtitle, date, content, url\n",
      "Columns kept: content_cleaned\n",
      "Total rows: 109\n",
      "Output saved to: all_urdu_moral_stories_cleaned.csv\n",
      "\n",
      "First few cleaned samples:\n",
      "                                     content_cleaned\n",
      "0  ارسلان خان شیر جنگل میں آرام کر رہا تھا کہ اس ...\n",
      "1  جاوید اقبال ایک دن دوستوں کا بیٹھے بیٹھے گاؤں ...\n",
      "2  محمد سراج الدین میں ایک بلی ہوں۔میرا رنگ سفید ...\n",
      "3  محمد فاروق دانش ”ارے بے وقوف! بات تو سنو․․․․“ ...\n",
      "4  فرحی نعیم سامنے والے اسلم انکل جب سے ابو جان س...\n"
     ]
    }
   ],
   "source": [
    "# Keep only the cleaned content column and save\n",
    "df_cleaned = df[['content_cleaned']].copy()\n",
    "\n",
    "# Save to new CSV with only cleaned content\n",
    "output_file_final = 'all_urdu_moral_stories_cleaned.csv'\n",
    "df_cleaned.to_csv(output_file_final, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Columns removed: title, subtitle, date, content, url\")\n",
    "print(f\"Columns kept: content_cleaned\")\n",
    "print(f\"Total rows: {len(df_cleaned)}\")\n",
    "print(f\"Output saved to: {output_file_final}\")\n",
    "print(f\"\\nFirst few cleaned samples:\")\n",
    "print(df_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "586929be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special Tokens Defined:\n",
      "EOS (End of Sentence):   U+FFF0 = '￰' (Unicode byte: 65520)\n",
      "EOP (End of Paragraph):  U+FFF1 = '￱' (Unicode byte: 65521)\n",
      "EOT (End of Story):      U+FFF2 = '￲' (Unicode byte: 65522)\n",
      "\n",
      "Tokens added successfully!\n",
      "Output saved to: all_urdu_moral_stories_with_tokens.csv\n",
      "\n",
      "Example with special tokens:\n",
      "ارسلان خان شیر جنگل میں آرام کر رہا تھا کہ اس نے بلی کو دیکھا تو اسے آواز دے کر بلایا۔￰شیر نے بلی سے پوچھا ”تم دیکھنے میں تو مجھ جیسی ہو لیکن تمہارا قد اتنا چھوٹا کیوں ہے؟￰“ بلی نے اداسی سے کہا، ”ظالم انسان نے میرا قد چھوٹا کر دیا ہے، ویسے میں رشتے میں تمہاری خالہ ہوں“۔￰ شیر نے یہ سنا تو غصے سے کہا،\n"
     ]
    }
   ],
   "source": [
    "# Define special tokens using unused Unicode bytes\n",
    "EOS = '\\uFFF0'  # End of Sentence\n",
    "EOP = '\\uFFF1'  # End of Paragraph\n",
    "EOT = '\\uFFF2'  # End of Story/Text\n",
    "\n",
    "print(\"Special Tokens Defined:\")\n",
    "print(f\"EOS (End of Sentence):   U+FFF0 = '{EOS}' (Unicode byte: {ord(EOS)})\")\n",
    "print(f\"EOP (End of Paragraph):  U+FFF1 = '{EOP}' (Unicode byte: {ord(EOP)})\")\n",
    "print(f\"EOT (End of Story):      U+FFF2 = '{EOT}' (Unicode byte: {ord(EOT)})\")\n",
    "\n",
    "def add_special_tokens(text):\n",
    "    \"\"\"Add special tokens to mark sentence, paragraph, and story ends\"\"\"\n",
    "    # Split by Urdu sentence endings and add EOS token\n",
    "    text = text.replace('۔', f'۔{EOS}')  # Period\n",
    "    text = text.replace('؟', f'؟{EOS}')  # Question mark\n",
    "    text = text.replace('!', f'!{EOS}')  # Exclamation\n",
    "    \n",
    "    # Split by newlines and add EOP token (paragraphs)\n",
    "    text = text.replace('\\n', f'{EOP}\\n')\n",
    "    \n",
    "    # Add EOT at the very end\n",
    "    text = text.rstrip() + EOT\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Load cleaned data and add special tokens\n",
    "df_cleaned = pd.read_csv('all_urdu_moral_stories_cleaned.csv')\n",
    "\n",
    "# Apply special tokens\n",
    "df_cleaned['content_with_tokens'] = df_cleaned['content_cleaned'].apply(add_special_tokens)\n",
    "\n",
    "# Save with special tokens\n",
    "output_file_tokens = 'all_urdu_moral_stories_with_tokens.csv'\n",
    "df_cleaned.to_csv(output_file_tokens, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"\\nTokens added successfully!\")\n",
    "print(f\"Output saved to: {output_file_tokens}\")\n",
    "print(f\"\\nExample with special tokens:\")\n",
    "print(df_cleaned['content_with_tokens'].iloc[0][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7567dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column removed: content_cleaned\n",
      "Column kept: content_with_tokens (renamed to 'content')\n",
      "Total rows: 109\n",
      "Output saved to: all_urdu_moral_stories_with_tokens.csv\n",
      "\n",
      "Final structure:\n",
      "                                             content\n",
      "0  ارسلان خان شیر جنگل میں آرام کر رہا تھا کہ اس ...\n",
      "1  جاوید اقبال ایک دن دوستوں کا بیٹھے بیٹھے گاؤں ...\n",
      "2  محمد سراج الدین میں ایک بلی ہوں۔￰میرا رنگ سفید...\n",
      "3  محمد فاروق دانش ”ارے بے وقوف!￰ بات تو سنو․․․․“...\n",
      "4  فرحی نعیم سامنے والے اسلم انکل جب سے ابو جان س...\n"
     ]
    }
   ],
   "source": [
    "# Remove content_cleaned column and keep only content_with_tokens\n",
    "df_final = pd.read_csv('all_urdu_moral_stories_with_tokens.csv')\n",
    "\n",
    "# Keep only the content_with_tokens column\n",
    "df_final = df_final[['content_with_tokens']].copy()\n",
    "\n",
    "# Rename column for clarity\n",
    "df_final.rename(columns={'content_with_tokens': 'content'}, inplace=True)\n",
    "\n",
    "# Save final version\n",
    "output_file_final = 'all_urdu_moral_stories_with_tokens.csv'\n",
    "df_final.to_csv(output_file_final, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"Column removed: content_cleaned\")\n",
    "print(f\"Column kept: content_with_tokens (renamed to 'content')\")\n",
    "print(f\"Total rows: {len(df_final)}\")\n",
    "print(f\"Output saved to: {output_file_final}\")\n",
    "print(f\"\\nFinal structure:\")\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed604d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
